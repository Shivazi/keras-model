{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(len(temp))\n",
    "print((temp[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length:  25000\n",
      "X_test length:  25000\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train length: \", len(x_train))\n",
    "print(\"X_test length: \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "print(x_train[0])\n",
    "print(\" \".join([index_to_word[x] for x in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: 0 Max value: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Min value:\", min(y_train), \"Max value:\", max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length:  238.71364\n",
      "Median sequence length:  178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "average_length = np.mean([len(x) for x in x_train])\n",
    "median_length = sorted([len(x) for x in x_train])[len(x_train) // 2]\n",
    "\n",
    "print(\"Average sequence length: \", average_length)\n",
    "print(\"Median sequence length: \", median_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (25000, 180)\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 180\n",
    "from keras.preprocessing import sequence\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "print('X_train shape: ', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1    14    22    16    43   530   973  1622  1385    65   458  4468\n",
      "    66  3941     4   173    36   256     5    25   100    43   838   112\n",
      "    50   670     2     9    35   480   284     5   150     4   172   112\n",
      "   167     2   336   385    39     4   172  4536  1111    17   546    38\n",
      "    13   447     4   192    50    16     6   147  2025    19    14    22\n",
      "     4  1920  4613   469     4    22    71    87    12    16    43   530\n",
      "    38    76    15    13  1247     4    22    17   515    17    12    16\n",
      "   626    18 19193     5    62   386    12     8   316     8   106     5\n",
      "     4  2223  5244    16   480    66  3785    33     4   130    12    16\n",
      "    38   619     5    25   124    51    36   135    48    25  1415    33\n",
      "     6    22    12   215    28    77    52     5    14   407    16    82\n",
      " 10311     8     4   107   117  5952    15   256     4     2     7  3766\n",
      "     5   723    36    71    43   530   476    26   400   317    46     7\n",
      "     4 12118  1029    13   104    88     4   381    15   297    98    32\n",
      "  2071    56    26   141     6   194  7486    18     4   226    22    21]\n",
      "1\n",
      "[    1   591   202    14    31     6   717    10    10 18142 10698     5\n",
      "     4   360     7     4   177  5760   394   354     4   123     9  1035\n",
      "  1035  1035    10    10    13    92   124    89   488  7944   100    28\n",
      "  1668    14    31    23    27  7479    29   220   468     8   124    14\n",
      "   286   170     8   157    46     5    27   239    16   179 15387    38\n",
      "    32    25  7944   451   202    14     6   717     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "print(x_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biswas/anaconda3/envs/lstm/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 79s 3ms/step - loss: 0.6637 - accuracy: 0.5991\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 79s 3ms/step - loss: 0.5911 - accuracy: 0.7079\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 79s 3ms/step - loss: 0.5457 - accuracy: 0.7427\n",
      "25000/25000 [==============================] - 19s 758us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Single layer LSTM example\n",
    "hidden_size = 32\n",
    "\n",
    "sl_model = Sequential()\n",
    "sl_model.add(Embedding(max_words, hidden_size))\n",
    "sl_model.add(LSTM(hidden_size, activation='tanh', dropout=0.2, recurrent_dropout=0.2))\n",
    "sl_model.add(Dense(1, activation='sigmoid'))\n",
    "sl_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 3\n",
    "sl_model.fit(x_train, y_train, epochs=epochs, shuffle=True)\n",
    "loss, acc = sl_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 648,353\n",
      "Trainable params: 648,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 648,353\n",
      "Trainable params: 648,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 656,673\n",
      "Trainable params: 656,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biswas/anaconda3/envs/lstm/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 148s 6ms/step - loss: 0.6243 - accuracy: 0.6500\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 149s 6ms/step - loss: 0.5516 - accuracy: 0.7373\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 148s 6ms/step - loss: 0.5962 - accuracy: 0.6521\n",
      "25000/25000 [==============================] - 35s 1ms/step\n",
      "Single layer model -- ACC 0.7764000296592712 -- LOSS 0.5150225333690643\n",
      "Double layer model -- ACC 0.7105200290679932 -- LOSS 0.5713413475036621\n"
     ]
    }
   ],
   "source": [
    "d_model = Sequential()\n",
    "d_model.add(Embedding(max_words, hidden_size))\n",
    "d_model.add(LSTM(hidden_size, activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "d_model.add(LSTM(hidden_size, activation='tanh', dropout=0.2, recurrent_dropout=0.2))\n",
    "d_model.add(Dense(1, activation='sigmoid'))\n",
    "d_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "d_model.summary()\n",
    "d_model.fit(x_train, y_train, epochs=epochs, shuffle=True)\n",
    "d_loss, d_acc = d_model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Single layer model -- ACC {} -- LOSS {}'.format(acc, loss))\n",
    "print('Double layer model -- ACC {} -- LOSS {}'.format(d_acc, d_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 656,673\n",
      "Trainable params: 656,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
